{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T20:48:44.349322Z",
     "start_time": "2025-05-12T20:48:43.791023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "import holidays\n",
    "\n",
    "class VisitPredictor:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.le_canal = LabelEncoder()\n",
    "        self.sucursales = []\n",
    "        self.horario_min = 9\n",
    "        self.horario_max = 21\n",
    "\n",
    "    def load_data(self, filepath):\n",
    "        # Cargar datos\n",
    "        df = pd.read_csv(r'/sucursales\\data\\mar-abr.csv', sep=',')\n",
    "        df['FECHA'] = pd.to_datetime(df['FECHA'], format='%d-%m-%Y')\n",
    "\n",
    "        # Filtrar horas relevantes (9am a 9pm)\n",
    "        df = df[(df['HORA'] >= self.horario_min) & (df['HORA'] <= self.horario_max)]\n",
    "\n",
    "        # Codificar canal\n",
    "        df['CANAL_2'] = self.le_canal.fit_transform(df['CANAL_2'])\n",
    "\n",
    "        # Extraer sucursales únicas\n",
    "        self.sucursales = df['COD_SUC'].unique().tolist()\n",
    "\n",
    "        return df\n",
    "\n",
    "    def preprocess_data(self, df):\n",
    "        # Crear características temporales\n",
    "        df['DIA_SEMANA'] = df['FECHA'].dt.dayofweek\n",
    "        df['DIA_MES'] = df['FECHA'].dt.day\n",
    "        df['MES'] = df['FECHA'].dt.month\n",
    "        df['ES_FINDE'] = df['FECHA'].dt.dayofweek // 5\n",
    "\n",
    "        # Agregar festivos de Argentina\n",
    "        ar_holidays = holidays.Argentina()\n",
    "        df['ES_FESTIVO'] = df['FECHA'].apply(lambda x: x in ar_holidays).astype(int)\n",
    "\n",
    "        # Agrupar por fecha, hora y sucursal para contar visitas\n",
    "        grouped = df.groupby(['COD_SUC', 'FECHA', 'HORA']).size().reset_index(name='VISITAS')\n",
    "        features = df.groupby(['COD_SUC', 'FECHA', 'HORA']).first().reset_index()\n",
    "        features = features[['COD_SUC', 'FECHA', 'HORA', 'DIA_SEMANA', 'DIA_MES', 'MES', 'ES_FINDE', 'ES_FESTIVO']]\n",
    "\n",
    "        final_df = pd.merge(grouped, features, on=['COD_SUC', 'FECHA', 'HORA'])\n",
    "\n",
    "        return final_df\n",
    "\n",
    "    def train_model(self, df):\n",
    "        # Preparar datos para entrenamiento\n",
    "        X = df[['COD_SUC', 'HORA', 'DIA_SEMANA', 'DIA_MES', 'MES', 'ES_FINDE', 'ES_FESTIVO']]\n",
    "        y = df['VISITAS']\n",
    "\n",
    "        # Dividir datos\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "        # Entrenar modelo XGBoost\n",
    "        self.model = xgb.XGBRegressor(\n",
    "            objective='reg:squarederror',\n",
    "            n_estimators=1000,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.7,\n",
    "            early_stopping_rounds=50,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        self.model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_test, y_test)],\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # Evaluar modelo\n",
    "        preds = self.model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        print(f\"MAE del modelo: {mae:.2f}\")\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def predict_next_week(self, sucursal):\n",
    "        # Generar fechas para los próximos 7 días\n",
    "        last_date = datetime.now().date()\n",
    "        dates = [last_date + timedelta(days=i) for i in range(1, 8)]\n",
    "\n",
    "        # Crear dataframe de predicción\n",
    "        pred_data = []\n",
    "        for date in dates:\n",
    "            for hora in range(self.horario_min, self.horario_max + 1):\n",
    "                dia_semana = date.weekday()\n",
    "                dia_mes = date.day\n",
    "                mes = date.month\n",
    "                es_finde = 1 if dia_semana >= 5 else 0\n",
    "\n",
    "                # Verificar si es festivo\n",
    "                ar_holidays = holidays.Argentina()\n",
    "                es_festivo = 1 if date in ar_holidays else 0\n",
    "\n",
    "                pred_data.append([\n",
    "                    sucursal, hora, dia_semana, dia_mes, mes, es_finde, es_festivo\n",
    "                ])\n",
    "\n",
    "        pred_df = pd.DataFrame(pred_data, columns=[\n",
    "            'COD_SUC', 'HORA', 'DIA_SEMANA', 'DIA_MES', 'MES', 'ES_FINDE', 'ES_FESTIVO'\n",
    "        ])\n",
    "\n",
    "        # Realizar predicciones\n",
    "        pred_df['VISITAS_PRED'] = self.model.predict(pred_df)\n",
    "        pred_df['FECHA'] = [dates[h//(self.horario_max-self.horario_min+1)] for h in range(len(pred_df))]\n",
    "\n",
    "        return pred_df[['COD_SUC', 'FECHA', 'HORA', 'VISITAS_PRED']]\n",
    "\n",
    "    def save_model(self, path):\n",
    "        joblib.dump({\n",
    "            'model': self.model,\n",
    "            'le_canal': self.le_canal,\n",
    "            'sucursales': self.sucursales\n",
    "        }, path)\n",
    "\n",
    "    def load_model(self, path):\n",
    "        data = joblib.load(path)\n",
    "        self.model = data['model']\n",
    "        self.le_canal = data['le_canal']\n",
    "        self.sucursales = data['sucursales']\n",
    "        return self\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = VisitPredictor()\n",
    "\n",
    "    # Cargar y preprocesar datos\n",
    "    df = predictor.load_data('mar-abr.csv')\n",
    "    processed_df = predictor.preprocess_data(df)\n",
    "\n",
    "    # Entrenar modelo\n",
    "    predictor.train_model(processed_df)\n",
    "\n",
    "    # Guardar modelo\n",
    "    predictor.save_model('visit_predictor_model.pkl')\n",
    "\n",
    "    # Ejemplo de predicción para sucursal 0\n",
    "    preds = predictor.predict_next_week(0)\n",
    "    print(\"\\nPredicciones para los próximos 7 días (Sucursal 0):\")\n",
    "    print(preds.head(10))"
   ],
   "id": "80db2f5e460dfe3a",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'FECHA'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3804\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m3805\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3806\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mindex.pyx:167\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mindex.pyx:196\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mKeyError\u001B[39m: 'FECHA'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 139\u001B[39m\n\u001B[32m    136\u001B[39m predictor = VisitPredictor()\n\u001B[32m    138\u001B[39m \u001B[38;5;66;03m# Cargar y preprocesar datos\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m139\u001B[39m df = \u001B[43mpredictor\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload_data\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mmar-abr.csv\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    140\u001B[39m processed_df = predictor.preprocess_data(df)\n\u001B[32m    142\u001B[39m \u001B[38;5;66;03m# Entrenar modelo\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 22\u001B[39m, in \u001B[36mVisitPredictor.load_data\u001B[39m\u001B[34m(self, filepath)\u001B[39m\n\u001B[32m     19\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mload_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, filepath):\n\u001B[32m     20\u001B[39m     \u001B[38;5;66;03m# Cargar datos\u001B[39;00m\n\u001B[32m     21\u001B[39m     df = pd.read_csv(\u001B[33mr\u001B[39m\u001B[33m'\u001B[39m\u001B[33mC:\u001B[39m\u001B[33m\\\u001B[39m\u001B[33mUsers\u001B[39m\u001B[33m\\\u001B[39m\u001B[33miazuaz\u001B[39m\u001B[33m\\\u001B[39m\u001B[33mPyCharmMiscProject\u001B[39m\u001B[33m\\\u001B[39m\u001B[33msucursales_2\u001B[39m\u001B[33m\\\u001B[39m\u001B[33mdata\u001B[39m\u001B[33m\\\u001B[39m\u001B[33mmar-abr.csv\u001B[39m\u001B[33m'\u001B[39m, sep=\u001B[33m'\u001B[39m\u001B[33m,\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m22\u001B[39m     df[\u001B[33m'\u001B[39m\u001B[33mFECHA\u001B[39m\u001B[33m'\u001B[39m] = pd.to_datetime(\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mFECHA\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m, \u001B[38;5;28mformat\u001B[39m=\u001B[33m'\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[33m-\u001B[39m\u001B[33m%\u001B[39m\u001B[33mm-\u001B[39m\u001B[33m%\u001B[39m\u001B[33mY\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m     24\u001B[39m     \u001B[38;5;66;03m# Filtrar horas relevantes (9am a 9pm)\u001B[39;00m\n\u001B[32m     25\u001B[39m     df = df[(df[\u001B[33m'\u001B[39m\u001B[33mHORA\u001B[39m\u001B[33m'\u001B[39m] >= \u001B[38;5;28mself\u001B[39m.horario_min) & (df[\u001B[33m'\u001B[39m\u001B[33mHORA\u001B[39m\u001B[33m'\u001B[39m] <= \u001B[38;5;28mself\u001B[39m.horario_max)]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001B[39m, in \u001B[36mDataFrame.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   4100\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.columns.nlevels > \u001B[32m1\u001B[39m:\n\u001B[32m   4101\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._getitem_multilevel(key)\n\u001B[32m-> \u001B[39m\u001B[32m4102\u001B[39m indexer = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4103\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[32m   4104\u001B[39m     indexer = [indexer]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3807\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[32m   3808\u001B[39m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc.Iterable)\n\u001B[32m   3809\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[32m   3810\u001B[39m     ):\n\u001B[32m   3811\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[32m-> \u001B[39m\u001B[32m3812\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m   3813\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[32m   3814\u001B[39m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[32m   3815\u001B[39m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[32m   3816\u001B[39m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[32m   3817\u001B[39m     \u001B[38;5;28mself\u001B[39m._check_indexing_error(key)\n",
      "\u001B[31mKeyError\u001B[39m: 'FECHA'"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T16:17:57.752437Z",
     "start_time": "2025-05-28T16:17:54.310438Z"
    }
   },
   "cell_type": "code",
   "source": "    !pip install prophet",
   "id": "1458aa446fb4fcee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: prophet in c:\\users\\iazuaz\\pycharmmiscproject\\.venv\\lib\\site-packages (1.1.6)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in c:\\users\\iazuaz\\pycharmmiscproject\\.venv\\lib\\site-packages (from prophet) (1.2.5)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\iazuaz\\pycharmmiscproject\\.venv\\lib\\site-packages (from prophet) (2.2.5)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in c:\\users\\iazuaz\\pycharmmiscproject\\.venv\\lib\\site-packages (from prophet) (3.10.1)\n",
      "Requirement already satisfied: pandas>=1.0.4 in c:\\users\\iazuaz\\pycharmmiscproject\\.venv\\lib\\site-packages (from prophet) (2.2.3)\n",
      "Requirement already satisfied: holidays<1,>=0.25 in c:\\users\\iazuaz\\pycharmmiscproject\\.venv\\lib\\site-packages (from prophet) (0.72)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\users\\iazuaz\\pycharmmiscproject\\.venv\\lib\\site-packages (from prophet) (4.67.1)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\iazuaz\\pycharmmiscproject\\.venv\\lib\\site-packages (from prophet) (6.5.2)\n",
      "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in c:\\users\\iazuaz\\pycharmmiscproject\\.venv\\lib\\site-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\iazuaz\\pycharmmiscproject\\.venv\\lib\\site-packages (from holidays<1,>=0.25->prophet) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\iazuaz\\pycharmmiscproject\\.venv\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\iazuaz\\pycharmmiscproject\\.venv\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\iazuaz\\pycharmmiscproject\\.venv\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\iazuaz\\pycharmmiscproject\\.venv\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\iazuaz\\pycharmmiscproject\\.venv\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\iazuaz\\pycharmmiscproject\\.venv\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\iazuaz\\pycharmmiscproject\\.venv\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (3.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\iazuaz\\pycharmmiscproject\\.venv\\lib\\site-packages (from pandas>=1.0.4->prophet) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\iazuaz\\pycharmmiscproject\\.venv\\lib\\site-packages (from pandas>=1.0.4->prophet) (2025.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\iazuaz\\pycharmmiscproject\\.venv\\lib\\site-packages (from tqdm>=4.36.1->prophet) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\iazuaz\\pycharmmiscproject\\.venv\\lib\\site-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T19:09:51.348186Z",
     "start_time": "2025-05-28T19:09:21.971957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install sklearn.preprocessing\n",
    "!pip install sklearn.ensemble"
   ],
   "id": "e1f4f0a2fd4002cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn.preprocessing\n",
      "  Downloading sklearn_preprocessing-0.1.0-py3-none-any.whl.metadata (70 bytes)\n",
      "Downloading sklearn_preprocessing-0.1.0-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: sklearn.preprocessing\n",
      "Successfully installed sklearn.preprocessing-0.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Could not find a version that satisfies the requirement sklearn.ensemble (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for sklearn.ensemble\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "727001e6c624fab"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
